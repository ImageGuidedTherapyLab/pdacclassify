---
title: "Binary Classification Analysis"
output: pdf_document
params:
  csvPath:            exampledata.csv
  outCsvName:        !r NULL
  target:             NULL
  positive_class:     NULL
  regexp:            !r "(Volume|Mean)" 
  fixed_inputs:      !r NULL
  exclude_inputs:    !r NULL
  nfold:             !r NULL
  foldID:            !r NULL
  leaveOneOut:       !r TRUE
  test_csv:          !r NULL
  rescale:           !r FALSE
  removeCorrelated:  !r TRUE
  cutoff:               0.7
  plot:              !r TRUE
  semisupervised:    !r FALSE
  kClusters:         !r as.numeric(9)
  genetic:           !r FALSE
  boruta:            !r FALSE
  univariate:        !r TRUE
  unipValThresh:     !r 0.05

---
## Version: BINARY CLASSIFIER

DOC: Usage - Rscript -e "rmarkdown::render( 'binary_analysis.RMD', output_file = './binary_exampleout.pdf', params = list( csvPath='exampledata.csv', target='survivalClass', positive_class='short', regexp='(VoxelNum|firstorder)', fixed_inputs='age',leaveOneOut=TRUE, nfold=5, foldID=1) )"


DOC: Debugging - set params in R shell:  params = list( csvPath='datalocation/pyradiomics_modeling.csv', target='MutationalStatus', positive_class='mut', inputs=NULL , leaveOneOut=TRUE, test_csv='datalocation/pyradiomicsout_experimentalcohort.csv', rescale=FALSE, removeCorrelated=TRUE, plot=TRUE, semisupervised=FALSE, kClusters=as.numeric(9), genetic=FALSE, boruta=TRUE, univariate=TRUE, unipValThresh=0.05 ),  copy block by block

TODO: semi-supervised feature and genetic variable selection

TODO: Compare to null model for imbalanced datasets





DOC: boxplot  https://www.r-bloggers.com/about-boxplot/ : the bottom and top of the box are always the 25th and 75th percentile (the lower and upper quartiles, respectively), and the band near the middle of the box is always the 50th percentile (the median). But the ends of the whiskers can represent several possible alternative values...”
In R’s default boxplot{graphics} code,

upper whisker = min(max(x), Q_3 + 1.5 * IQR) 
lower whisker = max(min(x), Q_1 – 1.5 * IQR)

where IQR = Q_3 – Q_1, the box length.
So the upper whisker is located at the *smaller* of the maximum x value and Q_3 + 1.5 IQR, 
whereas the lower whisker is located at the *larger* of the smallest x value and Q_1 – 1.5 IQR.


Compiled: `r format(Sys.time(), "%Y-%b-%d %H:%M:%S")` 

Target Variable: `r params$target`

Input File:      `r params$csvPath`

Target and inputs are column headings in csv file,
everything else is ignored



```{r libs, echo=FALSE, warning=FALSE}
params
options("width"=180)
# WIP reduce number of packages
libs <- c("caret", "kernlab", "knitr", "e1071", "magrittr", "rpart", "nnet", "parallel",
"randomForest", "MASS","cluster", "corrplot", "gridExtra","pROC")
# "xgboost", "Boruta", "leaps", "ranger", "subselect", 

invisible(lapply(libs, require,character.only=T))
set.seed(25)
```



```{r Loading Data, echo=TRUE, warning=FALSE, message=TRUE}

# load data
datFull <- read.csv(params$csvPath)

#error check
print(sprintf("target %s specified",params$target))
if(is.null(params$target)) stop("No target specified")

inputs <- union(params$fixed_inputs,
                grep(params$regexp, names(datFull),value=T))


print(sprintf("%d rows and %d columns read from csv file: %s", nrow(datFull), ncol(datFull), params$csvPath))
print(sprintf("%d inputs found with regexp parameter and fixed inputs", length(inputs)))


# remove excluded inputs if defined
if (!is.null(params$exclude_inputs)){
  inputs <- union( setdiff(inputs, grep(params$exclude_inputs, names(datFull),value=T)), params$fixed_inputs)
  print(sprintf("%d inputs remained after excluded inputs", length(inputs)))
} else {
  print("No excluded_inputs from parameters")
}


# remove unnecessary columns and clean NAs
datCrop <- datFull[,c(inputs,params$target)]


#remove incomplete cases
incompCases <- !complete.cases(datCrop)
print("The following rows are excluded for missing data:")
print(row.names(datFull)[incompCases])

datCompleteCases <- datCrop[!incompCases,]

if(nrow(datCompleteCases) < 5){
  stop("Less than 5 rows had no missing input values")
}

# remove inputs with NA or infinite values (should do nothing if complete cases was applied)
dat <- datCompleteCases[, (colSums(is.na(datCompleteCases)) == 0 ) & (sapply(datCompleteCases, function(x) sum(is.infinite(x)) ) == 0) ]


# subset based on validation set if provided
if(!is.null(params$foldID)){
  set.seed(5)
#TODO: translate validation indices back to full data frame

  if(!("validationFolds" %in% names(datFull)) ){
    datFull$validationFolds <- rep(NA,nrow(datFull))
    validationFolds <- createFolds(dat[,params$target],k=params$nfold,list=F)

    # add kfold indices to data matrix
    dat$validationFolds <- validationFolds
    datFull[row.names(dat),"validationFolds"] <- validationFolds

  } else {
    print(sprintf("validationFolds column already exists in the csv, reading it instead of generating folds."))
    dat$validationFolds <- datFull[row.names(dat),"validationFolds"]
  }

  validationidx <- which(validationFolds == params$foldID) #gives row numbers (not row names), this will not match the original (nonfiltered) data
  print(paste("Leaving out ", params$validationID, " fold number ", params$foldID,sep=""))

  #bad code: order of these two lines matters
  validationdat <- dat[validationidx,]

  print("removing validation fold from data frame")
  dat <- dat[-validationidx,]
}
print("summary of classes")
print(summary(dat[,params$target]))

# Legacy code: old script uses dsraw instead of dat
dsraw <- dat

###### OLD DATA LOADING CODE  ###########
#datamatrix <- read.csv(params$csvPath)
#datamatrix$phenotype  = as.factor(ifelse(datamatrix[,"phenotype"] == 1 , "ACC", "ACA")) 
#allinputs <- colnames(datamatrix)
#inputcols <- allinputs [grep("original_*",colnames(datamatrix))]
#if(!is.null(params$inputs)){
#  print(" manually select columns")
#  inputcols <- allinputs [params$inputs]
#} 

# Set model parameters
modelparams <- list(#tree = list(method  = "rpart",
                    #            #tuneGrid = data.frame(.cp = 0.01),
                    #            parms   = list(split="information")
                    #          ),
                    forest = list(method      = "rf",
                                  ntree       = 500,
                                 #tuneGrid    = data.frame(.mtry = mtry),
                                 #replace    = TRUE,
                                 #na.action  = randomForest::na.roughfix,
                                 importance  = FALSE,
                                 predict.all = FALSE
                                 ),
                     #na.action removed since "na.action" is used in caret
                    
                     #xgboost = list(method = "xgbLinear"),
 
                    # nnet = list(method = "nnet",
                    #             #tuneGrid=data.frame(.size = 10, .decay = 0),
                    #             #linout  = TRUE,
                    #             skip    = TRUE,
                    #             MaxNWts = 10000,
                    #             trace   = FALSE,
                    #             maxit   = 100),
                     
                     svm = list(method = "svmRadial"),
                     logit = list(method = "glm")
)



```
## Pre-processing data: 
By default removes columns with zero variance and discards variables correlated >0.8
```{r Pre-Processing Data, echo=FALSE}
#  methods: zv removes zero-variance columns
#           corr removes highly correlated columns
#           center/scale recenters variables


#coerce to factor if needed
# careful with factor levels
print(sprintf("target variable %s ",params$target) )  



if(!is.factor(dsraw[,params$target])){
  dsraw[params$target]<- as.factor(dsraw[,params$target])
  print("changed target variable to factor")
  print(sprintf("initial level: %s", levels(dsraw[,params$target])))

  if(!is.null(params$positive_class)) {
  positive_class <- params$positive_class
  } else {
#   stop(params$positive_class)
  positive_class <- "case"
  }

  levels(dsraw[,params$target]) <- c("control",positive_class)  
  print(sprintf("reassigned target levels to: %s", levels(dsraw[,params$target])))
}

if(!is.null(params$positive_class)) {
  positive_class <- params$positive_class
} else {
  positive_class <- levels(dsraw[,params$target])[2]
  print(sprintf("assuming positive class is: %s", positive_class))
}

#check for positive class in factor levels
if(!(positive_class %in% levels(dsraw[,params$target])) ){
  stop(sprintf("positive class %s  not found in levels of target variable %s", positive_class, levels(dsraw[,params$target])))
}


#check if binary
if(dsraw[,params$target] %>% levels %>% length !=2){
    stop("Target must have two levels")
}   

#rename positive class if needed
#levels(dsraw[,params$target])<- c("control","case")
#positive_class <- "case"


#remove columns where all values are NA
# REMOVE ROWS WITH NA

#narows <- sum(!complete.cases(dsraw))
#nacols <- sum(colSums(is.na(dsraw)) == nrow(dsraw))
#cat(sprintf("Removing %d rows for missing values\nRemoving %d NA columns",narows,nacols) )  

#dsraw <- dsraw[complete.cases(dsraw),colSums(is.na(dsraw))<nrow(dsraw)]

#reduced input set
#inputs <- setdiff(names(dsraw),params$target)

ppMethods <- "zv"
if(params$rescale)          {ppMethods <- c(ppMethods,"center","scale")}
if(params$removeCorrelated) {ppMethods <- c(ppMethods, "corr")}

#first remove zero variance (caret bug workaround)
pp <- preProcess(dsraw[inputs], method = "zv")
ds <- cbind(predict(pp, newdata = dsraw[inputs]),dsraw[params$target])

# reduce input set after correlation reduction
#Filteredinputs <- setdiff(names(ds), params$target)
Filteredinputs <- names(ds)[names(ds) %in% inputs]
pp <- preProcess(predict(pp, newdata = ds[Filteredinputs]), method = ppMethods, cutoff=0.8)

#get reduced input set/dataset
ds <- cbind(predict(pp, newdata = ds[Filteredinputs]),ds[params$target])
Filteredinputs <- setdiff(names(ds), params$target)


# WIP: Clustering for semi-supervised analysis with kClusters
if(params$semisupervised){
cat(paste("Clustering into ", params$kClusters, " clusters... By unsupervised random forest\n\n"))
rfUL <- randomForest(x=ds[,Filteredinputs],
                     ntree = 500,
                     replace=FALSE)
ds <- cbind(ds, clusters.conv = pam(1-rfUL$proximity, k = params$kClusters, diss = TRUE, cluster.only = TRUE))
ds$clusters.conv <- as.factor(ds$clusters.conv) #change to factor not int
Filteredinputs <- setdiff(names(ds),params$target)
}

```

## Pre-Processing results: 
Started with `r length(inputs)` non-NA variables.

```{r,echo=FALSE}
pp
```
`r length(Filteredinputs)` remained after pre-processing

## Variable Selection: 

Default is Boruta and Wilcoxon test (P value cutoff `r params$unipValThresh`/ `r length(Filteredinputs)`). Wilcoxon currently only tests numeric input variables

```{r Performing Variable Selection, echo=FALSE, warning=FALSE, fig.width=8, fig.height=8}

# Variable selection 
variableSelections <- list() #list(all=Filteredinputs)

#if <30 variables use all of them
if(Filteredinputs %>% length <= 30){
  variableSelections[["all"]] <- Filteredinputs

  correlations <- cor(Filter(is.numeric,ds[variableSelections$all]), use="pairwise")
   corrord <- order(correlations[1,])
   correlations <- correlations[corrord,corrord]
   corrplot(correlations,
   title = "Correlations for all variables",
   mar = c(1,2,2,0)  )
   print(" ")
  }

#genetic
if(params$genetic){
gen <- genetic(cor(ds[,Filteredinputs]), 4) #manually selected 4 outputs
variableSelections$genetic <- names(ds[,Filteredinputs])[gen$bestsets]
print("Genetic variable selections:")
print(variableSelections$genetic)

correlations <- cor(Filter(is.numeric,ds[variableSelections$genetic]), use="pairwise")
   corrord <- order(correlations[1,])
   correlations <- correlations[corrord,corrord]
   corrplot(correlations,
   title = "Correlations for Genetic method",
   mar = c(1,2,2,0)  )

}

#univariate (currently only works for numeric variables)
if(params$univariate){

nums <- sapply(ds[Filteredinputs],is.numeric)
nums <- names(nums)[nums] #get names not T/F
pvals <- lapply(nums,
       function(var) {          
           formula    <- as.formula(paste(var, "~", params$target))
           test <- wilcox.test(formula, ds[, c(var, params$target)])
           test$p.value #could use 1-pchisq(test$statistic, df= test$parameter)
       })
names(pvals) <- nums

variableSelections$univariate <- setdiff(Filteredinputs, nums[pvals > params$unipValThresh]) #discard variables above threshold

if(variableSelections$univariate %>% length > 1 & params$plot){
correlations <- cor(Filter(is.numeric,ds[variableSelections$univariate]), use="pairwise")
#   corrord <- order(correlations[1,])
#   correlations <- correlations[corrord,corrord]
   corrplot(correlations,
   title = "Correlations for Univariate method",
   mar = c(1,2,2,0),
   order="hclust"  )
   

#par(mfrow=c(length(variableSelections$univariate),1))
for(iii in 1:length(variableSelections$univariate)){
boxplot( as.formula( paste(variableSelections$univariate[[iii]], "~", params$target) ),
         data=ds,
         ylab=paste(variableSelections$univariate[[iii]]),
         main=sprintf("Wilcoxon Rank Sum test P = %0.3e",pvals[variableSelections$univariate[[iii]]]),
         mar=c(12,1,0,0)
       )

 univariable= ds[variableSelections$univariate[[iii]]]
 cat(setdiff(levels(ds[,params$target]),params$positive_class), 'summary\n')
 print(summary(univariable[which(ds[,params$target] != params$positive_class ),]))
 cat('\n')
 cat(params$positive_class, 'summary\n')
 print(summary(univariable[which(ds[,params$target] == params$positive_class ),]))
 cat('\n')
}# end boxplot
} #end if >0 variables
} #end if params$univariate



#boruta
if(params$boruta){
bor <- Boruta(x=ds[,Filteredinputs], y=ds[,params$target], pValue=.35)
variableSelections$boruta <- names(ds[,Filteredinputs])[which(bor$finalDecision == "Confirmed")]

print("Finished Boruta variable selection")
print(bor)


if(length(variableSelections$boruta) > 1 & params$plot){

correlations <- cor(Filter(is.numeric,ds[variableSelections$boruta]), use="pairwise")
#   corrord <- order(correlations[1,])
#   correlations <- correlations[corrord,corrord]
   corrplot(correlations,
   title = "Correlations for Boruta method",
   mar = c(1,2,2,0),
   order = "hclust"  )
}


if(length(variableSelections$boruta) > 0 & params$plot){
#par(mfrow=c(length(variableSelections$boruta),1))
for(iii in 1:length(variableSelections$boruta)){
boxplot( as.formula( paste(variableSelections$boruta[[iii]], "~", params$target) ),
         data=ds,
         ylab=paste(variableSelections$boruta[[iii]]),
         mar=c(12,1,0,0),
         main=sprintf("Wilcoxon Rank Sum test P = %0.3e",pvals[variableSelections$boruta[[iii]]])
       )
 borutavariable= ds[variableSelections$boruta[[iii]]]
 cat(setdiff(levels(ds[,params$target]),params$positive_class), 'summary\n')
 print(summary(borutavariable[which(ds[,params$target] != params$positive_class ),]))
 cat('\n')
 cat(params$positive_class, 'summary\n')
 print(summary(borutavariable[which(ds[,params$target] == params$positive_class ),]))
 cat('\n')
}# end boxplots
} #end if >0 variables
} #end if params$boruta


```


```{r Univariate selection, echo=FALSE}

#print results and error handle if no significant variables
if(params$univariate){
  if(length(variableSelections$univariate) == 0){ 
    cat(sprintf("No P values < %.5f\n", 0.2/length(nums)))
    variableSelections$univariate <- NULL
    } 
   
    pvaltable <- data.frame(Variable = Filteredinputs[pvals<.2], 
                        P_value = unlist(pvals[pvals<.2] )
                        )
    pvaltable <- pvaltable[order(pvaltable$P_value, decreasing=F),]
    cat("Listing variables with WILCOXON RANK SUM test P value < 0.2")
    kable(pvaltable, format = "markdown", row.names=F)
    }

```




# Modeling using `r names(modelparams)`.
Use Leave-one-out cross validation: `r params$leaveOneOut`


```{r Modeling (may take some time), echo=FALSE, warning=FALSE, message=FALSE}

#WIP: consider using metric=roc for binary classification

#Modeling, dataparams are arguements to caret::train
modelformula <- as.formula(paste(params$target,"~."))
dataparams   <- list(form = modelformula,
#                      data = ds[,c(params$target,Filteredinputs)],
                      metric="Accuracy", #other option: AUC?
                      trControl=trainControl(allowParallel  = T,
                                             method = ifelse(params$leaveOneOut,"LOOCV", "repeatedcv"),
                                             classProbs=TRUE,
                                             #returnResamp = "final",
                                             #number = 10,
                                             #repeats= 5,
                                             verboseIter = F) # use method="none" to disable grid tuning for speed
                     )  
caretparams      <- lapply(modelparams,function(x) c(dataparams,x))

#initialize outputs
models    <- list()
acc <- list()

for(jjj in 1:length(variableSelections)){
modeldata  <- ds[,c(params$target,variableSelections[[jjj]])]

# RE seeding: Hawthorn et al, "The design and analysis of benchmark experiments" (2005)

for (iii in 1:length(modelparams)){
model_name <-paste(names(variableSelections)[jjj], names(modelparams)[iii],sep="_")
#print(paste("Training model", iii, "of", (length(modelparams)*length(variableSelections)), ":", model_name, sep=" "))
set.seed(3141) #seed before train to get same subsamples
invisible(  models[[model_name]] <- do.call(caret::train, c(caretparams[[iii]], list(data=modeldata)))  )

metric <- models[[model_name]]$metric

#get best acuracy manually for LOOCV
acc[[model_name]] <- max(models[[model_name]]$results[metric])

}


}


```


```{r Finding best model and plotting, echo = FALSE, fig.width=8, fig.height=10}
if(params$leaveOneOut){
  maxacc <- max(unlist(acc))
  maxmodels <- names(which(acc==maxacc))

  #plot
  par(mar=c(8,5,1,1))
  barplot(unlist(acc),las=2, ylim=c(0,1),
    ylab=paste("training set LOOCV",metric))
  
} else {
  rs <- resamples(models)
  print(summary(object = rs))
  
  acc        <- rs$values[,grepl(rs$metrics[1], names(rs$values))]
  names(acc) <- rs$models
  maxacc <- max(apply(acc,2,mean))
  maxmodels <- rs$models[apply(acc,2,mean)==maxacc]
  
  # plot +1 to col arg keeps one box from being black
  par(mar=c(8,5,1,1))
  boxplot(acc,col=(as.numeric(as.factor(rs$methods))+1), las=2,
    ylab=paste("training set cross-validation",metric) )
  legend("bottomright", legend=unique(rs$methods),
    fill=(as.numeric(as.factor(rs$methods))+1) )
}

#get best accuracy
#cat(paste("best model(s): ", maxmodels, "\n"))
#cat(sprintf("%s: %.4f \n", metric, maxacc))
#lapply(maxmodels, function(x) models[[x]])
```

Best model(s): `r maxmodels`

`r sprintf("%s: %.4f", metric, maxacc)`

```{r Output model,echo = FALSE}
lapply(maxmodels, function(x) models[[x]])
```

```{r if LOOCV CV plot ROC,echo = FALSE, fig.width=8, fig.height=10}
if(params$leaveOneOut){
  print(paste("Building ROC Curve for model", maxmodels[[1]]))
  #recursiely subset
  bestmod <- models[[maxmodels[[1]]]] #pick first by default
  modpars <- bestmod$bestTune
  results <- bestmod$pred
  
  #filter predictions on best model
  for(kkk in 1:length(modpars)){
    results <- subset(results, results[,names(modpars)[kkk]]==modpars[,kkk])
  }
  
  print(caret::confusionMatrix(results$pred, reference = results$obs, positive = params$positive_class))
  ROC1 <- roc(response=results$obs,
              predictor = results[,params$positive_class],
              levels = c(setdiff(
                levels(results$obs), params$positive_class),
                         params$positive_class))
  print(ROC1)
  plot(ROC1, print.auc=T, print.auc.y = 0.2, print.auc.x = 0.5)
  # results is a frame with LOOCV data
  
  #best threshold based on sum of sens/spec
  kable(coords(roc=ROC1, x = "best", ret=c('threshold','sens', 'spec')))
  
}
```

```{r write csv with validation predictions, echo=FALSE}
#write cross-validation predictions


if(!is.null(params$foldID)){
  trainingpredname <- paste("trainindPreds_exceptfold",params$foldID,sep="")

  if(trainingpredname %in% names(datFull)){
    print(sprintf("cross-validation predictions for fold %s already found, compare differences below:", params$foldID))
    print("existing predictions (may be out of order):")
    kable(data.frame(existing=datFull[rownames(dat),trainingpredname],new=as.character(results$pred)))

  } else {
  datFull[trainingpredname] <- NA
  datFull[rownames(dat)[results$rowIndex],trainingpredname] <- as.character(results$pred)  #trickey line of code since results$rowIndex referes to rows of dat not datFull
    }

} else { #if no validation fold, write all predictions
  trainingpredname <- "trainingPreds"
  datFull[trainingpredname] <- NA
  datFull[rownames(dat)[results$rowIndex],trainingpredname] <- as.character(results$pred)  #trickey line of code since results$rowIndex referes to rows of dat not datFull
}


# write validation predictions
if(!is.null(params$foldID)){

predname <- paste("validationPreds_fold",params$foldID,sep="")


  if(predname %in% names(datFull)){
    print(sprintf("Validation predictions for fold %s already found, compare differences below:", params$foldID))
    print("existing predictions:")
    print(datFull$predname)
  } else {

datFull[predname] <- NA
datFull[which(datFull$validationFolds == params$foldID), predname] <- validationpreds
  }
}

print("summary of predictions:")

if(!is.null(params$foldID)){
  kable(datFull[,c(params$target,predname,trainingpredname)])
} else {
  kable(datFull[,c(params$target,trainingpredname)])
}


if(is.null(params$outCsvName)){
  print("No output csv file specified")

# Option to auto generate csv name
#  if(!is.null(params$foldID)){
#    outCsv <- sub(".csv",sprintf("_Fold%s_validation.csv",params$foldID),basename(params$csvPath)) 
#  } else {
#    outCsv <- sub(".csv","_no_validation.csv",basename(params$csvPath))
#  }

} else {
    outCsv <- params$outCsvName
}

print(sprintf("writing csv with validation predictions to %s", outCsv))
write.csv(datFull,outCsv,row.names=F)


```



## Testing best model on external validataion cohort:
```{r experimental cohort, echo = FALSE}

if(!is.null(params$test_csv)){
cat("Reading validation dataset:\n", params$test_csv)
full_data <- read.csv(params$test_csv)

bestModelInputs <- names(bestmod$trainingData[-1])

cat(c("Best model using inputs:", paste(bestModelInputs,collapse="\n"),"\n"))

sub_data <- full_data[,c(bestModelInputs, params$target)]

cat(sprintf("Number of cases ommitted for missing values %d out of %d\n", sum(!complete.cases(sub_data)), nrow(sub_data)))

new_data = sub_data[complete.cases(sub_data),]

preds <- predict(object=bestmod$finalModel,newdata = new_data,type="prob")

kable(preds)
} else {cat("No validation dataset provided")}


```






